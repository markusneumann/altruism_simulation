\@doanenote {1}
macro:->These
simulations
were
implemented
in
\texttt
{R},
version
4.0.1.
\@endanenote 
\@doanenote {2}
macro:->The
Supplemental
Information
contains
pseudo-code
for
the
simulation,
along
with
a
more
detailed
description.
The
full
replication
code
is
available
at:
\url
{https://github.com/markusneumann/altruism_simulation}
\@endanenote 
\@doanenote {3}
macro:->At
the
end
of
an
example
simulation
run,
players
in
a
network
of
$N=300$
with
default
parameters
hold,
on
average,
non-neutral
opinions
about
64.8
other
players.
In
a
network
of
$N=20,000$,
this
number
increases
to
72.3.
This
relatively
modest
increase
is
due
to
the
fact
that
players
are
clustered,
and
an
increase
in
population
leads
to
an
increase
in
the
number
of
clusters
much
more
so
than
an
increase
in
their
size.
Note
that
it
is
possible
they
also
heard
both
positive
and
negative
things
about
a
few
others,
which
might
have
balanced
out
to
a
score
of
zero,
which
wouldn't
be
reflected
in
these
numbers.
Given
that
according
to
\cite
{Dunbar1998},
humans
can
only
know
about
150
people
reasonably
well,
it
is
quite
plausible
that
the
actors
in
this
game
manage
to
keep
track
of
the
reputations
of
about
half
this
number.
\@endanenote 
\@doanenote {4}
macro:->Initially,
$s_{ij}=0$
for
everyone.
This
means
that
not
knowing
another
player
corresponds
to
being
indifferent
about
them.
\@endanenote 
\@doanenote {5}
macro:->This
is
another,
albeit
much
smaller
difference
to
at
least
some
of
the
literature,
in
which
players
are
selected
randomly,
as
opposed
to
everyone
getting
one
shot
at
the
game
per
round.
Conceptually,
this
really
makes
no
difference,
the
main
reason
I
handle
it
this
way
is
because
it
can
be
implemented
in
a
more
computationally
efficient
manner.
My
method
of
image
score
dissemination
is
quite
demanding
on
processing
resources,
so
efficiency
is
important.
\@endanenote 
\@doanenote {6}
macro:->In
addition
to
replacing
the
flawed
concept
of
perfect
information
with
a
much
more
realistic
one,
this
approach
also
corrects
a
minor
mathematical
artifact
in
the
conventional
method:
Once
a
player
has
attained
the
highest
possible
image
score,
he
has
no
incentive
to
cooperate
further,
because
it
won't
benefit
him.
Consequently,
the
only
rational
choice
is
to
defect
(although
this
strategy
is
usually
not
even
implemented,
which
means
players
are
just
downright
'wasteful'
and
irrational).
Therefore,
even
an
altruistically-minded
person
would
always
oscillate
between
the
highest
and
second
highest
image
score.
Clearly,
this
is
a
little
odd.
In
my
methodology,
this
never
becomes
a
problem.
Even
a
player
who
has
always
cooperated
will
(virtually)
always
have
someone
in
his
immediate
or
at
least
proximate
neighborhood
who
has
not
heard
about
his
good
deeds
yet.
Consequently
there
is
still
an
incentive
to
be
cooperative.
\@endanenote 
\@doanenote {7}
macro:->For
the
generation
of
a
network
via
the
Watts-Strogatz
model,
the
R
package
\texttt
{igraph},
version
1.2.5,
is
used.
\@endanenote 
\@doanenote {8}
macro:->Although
my
argument
specifically
centers
around
the
Watts-Strogatz
model
and
its
small-world
property,
I
also
experimented
with
two
other
frequently
used
random
graph
models:
The
Barabasi-Albert
model,
and
the
Erd\H
{o}s-R\'{e}nyi
model.
These
models
do
not
have
the
same
small-world
properties
as
the
Watts-Strogatz
model.
Since
my
argument
centers
around
the
role
of
clustering,
which
requires
the
small-world
property
to
be
controllable
(which
can
be
done
in
the
Watts-Strogatz
model
through
the
parameter
$p$),
the
results
are
not
sufficiently
relevant
to
be
included
in
the
paper.
\@endanenote 
\@doanenote {9}
macro:->In
the
original
notation
style
of
\cite
{Watts1998},
this
parameter
is
referred
to
as
$k$.
However,
since
this
letter
already
denotes
the
players'
strategies
here,
I
use
$l$
as
a
substitute.
\@endanenote 
\@doanenote {10}
macro:->The
results
for
the
other
network
parameter
$l$
can
be
found
in
Figure
\ref
{WS_300_l_100sims}
in
Appendix
B.
The
neighborhood
coefficient
does
not
appear
to
affect
altruism.
\@endanenote 
